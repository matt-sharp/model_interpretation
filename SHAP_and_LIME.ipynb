{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #for manipulating data\n",
    "import numpy as np  #for manipulating data\n",
    "import sklearn  #for building models\n",
    "import xgboost as xgb  #for building models\n",
    "import sklearn.ensemble  #for building models\n",
    "from sklearn.model_selection import train_test_split  #for creating a hold-out sample\n",
    "import lime  #LIME package\n",
    "import lime.lime_tabular  #the type of LIIME analysis weâ€™ll do\n",
    "import shap  #SHAP package\n",
    "import time  #some of the routines take a while, so we monitor the time\n",
    "import os  #needed to use Environment Variables in Domino\n",
    "import matplotlib.pyplot as plt  #for custom graphs at the end\n",
    "import seaborn as sns  #for custom graphs at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap.__version__)\n",
    "print(xgb.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Boston Housing Data\n",
    "\n",
    "We are trying to predict median value of owner-occupied homes in $1000s. The data comes from sklearn, so we can get more details about the columns from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.boston()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.datasets.load_boston().DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train({'objective':'reg:linear'}, xgb.DMatrix(X_train, label=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_xgb = sklearn.ensemble.GradientBoostingRegressor()\n",
    "sk_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SHAP Explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP has the following explainers: deep, gradient, kernel, linear, tree, sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerXGB = shap.TreeExplainer(xgb_model)\n",
    "shap_values_XGB_test = explainerXGB.shap_values(X_test)\n",
    "shap_values_XGB_train = explainerXGB.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree on Scikit GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerSKGBT = shap.TreeExplainer(sk_xgb)\n",
    "shap_values_SKGBT_test = explainerSKGBT.shap_values(X_test)\n",
    "shap_values_SKGBT_train = explainerSKGBT.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainerRF = shap.TreeExplainer(rf)\n",
    "shap_values_RF_test = explainerRF.shap_values(X_test)\n",
    "shap_values_RF_train = explainerRF.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must use Kernel method on KNN\n",
    "\n",
    "Summarizing the data with k-Means is a way to speed up the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rather than use the whole training set to estimate expected values, we summarize with\n",
    "a set of weighted kmeans, each weighted by the number of points they represent.\n",
    "Running without the kmeans took 1 hr 6 mins 7 sec. \n",
    "Running with the kmeans took 2 min 47 sec.\n",
    "Boston Housing is a very small dataset.\n",
    "Running SHAP on models that require Kernel method and have a good amount of data becomes prohibitive. \n",
    "\"\"\"\n",
    "X_train_summary = shap.kmeans(X_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using kmeans\n",
    "t0 = time.time()\n",
    "explainerKNN = shap.KernelExplainer(knn.predict, X_train_summary)\n",
    "shap_values_KNN_test = explainerKNN.shap_values(X_test)\n",
    "shap_values_KNN_train = explainerKNN.shap_values(X_train)\n",
    "t1 = time.time()\n",
    "timeit=t1-t0\n",
    "timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without kmeans a test run took 3967.6232330799103 seconds\n",
    "\"\"\"\n",
    "t0 = time.time()\n",
    "explainerKNN = shap.KernelExplainer(knn.predict, X_train)\n",
    "shap_values_KNN_test = explainerKNN.shap_values(X_test)\n",
    "shap_values_KNN_train = explainerKNN.shap_values(X_train)\n",
    "t1 = time.time()\n",
    "timeit=t1-t0\n",
    "timeit \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the SHAP values into dataframes so we can use them later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "df_shap_XGB_test = pd.DataFrame(shap_values_XGB_test, columns=X_test.columns.values)\n",
    "df_shap_XGB_train = pd.DataFrame(shap_values_XGB_train, columns=X_train.columns.values)\n",
    "# Scikit GBT\n",
    "df_shap_SKGBT_test = pd.DataFrame(shap_values_SKGBT_test, columns=X_test.columns.values)\n",
    "df_shap_SKGBT_train = pd.DataFrame(shap_values_SKGBT_train, columns=X_train.columns.values)\n",
    "# Random Forest\n",
    "df_shap_RF_test = pd.DataFrame(shap_values_RF_test, columns=X_test.columns.values)\n",
    "df_shap_RF_train = pd.DataFrame(shap_values_RF_train, columns=X_train.columns.values)\n",
    "# KNN\n",
    "df_shap_KNN_test = pd.DataFrame(shap_values_KNN_test, columns=X_test.columns.values)\n",
    "df_shap_KNN_train = pd.DataFrame(shap_values_KNN_train, columns=X_train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LIME Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a feature has 10 or less unique values then treat it as categorical\n",
    "categorical_features = np.argwhere(np.array([len(set(X_train.values[:,x])) \n",
    "                                             for x in range(X_train.values.shape[1])]) <= 10).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME has one explainer for all models\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, \n",
    "                                                   feature_names=X_train.columns.values.tolist(), \n",
    "                                                   class_names=['price'], \n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   verbose=True, \n",
    "                                                   mode='regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining an Instance (local interpretability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an instance to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.random.randint(0, X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional, set j manually\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize js\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainerXGB.expected_value, shap_values_XGB_test[j], X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-the-box LIME cannot handle the requirement of XGBoost to use xgb.DMatrix() on the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict function input doesn't jive wtih LIME\n",
    "xgb_model.predict(xgb.DMatrix(X_test.iloc[[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will throw an error\n",
    "\"\"\"\n",
    "expXGB = explainer.explain_instance(X_test.values[j], xgb_model.predict, num_features=5)\n",
    "expXGB.show_in_notebook(show_table=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn GBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainerSKGBT.expected_value, shap_values_SKGBT_test[j], X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expSKGBT = explainer.explain_instance(X_test.values[j], sk_xgb.predict, num_features=5)\n",
    "expSKGBT.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainerRF.expected_value, shap_values_RF_test[j], X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.values[j], rf.predict, num_features=5)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainerKNN.expected_value, shap_values_KNN_test[j], X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.values[j], knn.predict, num_features=5)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance plot via SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_XGB_train, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar to variable importance, this shows the SHAP values for every instance from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_XGB_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Influence or Dependency Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default SHAP dependency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_plt = shap.dependence_plot(\"LSTAT\", shap_values_XGB_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following modifies the default graph a bit to (1) highlight the jth instance with a black dot and (2) pick the color by variable ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = column of interest as string, column for coloring as string, df of our data, SHAP df, \n",
    "#          x postion of the black dot, y position of the black dot\n",
    "\n",
    "def dep_plt(col, color_by, base_actual_df, base_shap_df, overlay_x, overlay_y):\n",
    "    cmap=sns.diverging_palette(260, 10, sep=1, as_cmap=True) #seaborn pallete\n",
    "    f, ax = plt.subplots()\n",
    "    points = ax.scatter(base_actual_df[col], base_shap_df[col], c=base_actual_df[color_by], s=20, cmap=cmap)\n",
    "    f.colorbar(points).set_label(color_by)\n",
    "    ax.scatter(overlay_x, overlay_y, color='black', s=50)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"SHAP value for \" + col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of model inputs in order of SHAP importance\n",
    "imp_cols = df_shap_XGB_train.abs().mean().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# loop through this list to show top 3 dependency plots\n",
    "for i in range(0, len(imp_cols)):\n",
    "    #plot the top var and color by the 2nd var\n",
    "    if i == 0 : \n",
    "        dep_plt(imp_cols[i], \n",
    "                imp_cols[i+1], \n",
    "                X_train, \n",
    "                df_shap_XGB_train,\n",
    "                X_test.iloc[j,:][imp_cols[i]], \n",
    "                df_shap_XGB_test.iloc[j,:][imp_cols[i]])\n",
    "    #plot the 2nd and 3rd vars and color by the top var\n",
    "    if (i > 0) and (i < 3) : \n",
    "        dep_plt(imp_cols[i], \n",
    "                imp_cols[0], \n",
    "                X_train, \n",
    "                df_shap_XGB_train,\n",
    "                X_test.iloc[j,:][imp_cols[i]], \n",
    "                df_shap_XGB_test.iloc[j,:][imp_cols[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nikola": {
   "date": "2017-09-09 21:09:01 UTC+10:00",
   "slug": "test-slug",
   "title": "Using SHAP and LIME python libraries to Explain Black Box Models"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
